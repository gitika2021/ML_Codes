{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\udde0 LSTM GPU Memory Estimator\n", "This notebook estimates GPU memory usage for LSTM models based on input and model parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def estimate_lstm_gpu_memory(batch_size, seq_length, input_dim, hidden_dim, num_layers,\n", "                              dtype_bytes=4, bidirectional=False, model_param_MB_fixed=5):\n", "    \"\"\"\n", "    Estimate GPU memory usage for an LSTM model on time series data.\n", "\n", "    Returns: input_MB, activation_MB, total_MB, total_GB\n", "    \"\"\"\n", "    input_MB = batch_size * seq_length * input_dim * dtype_bytes / (1024 ** 2)\n", "    direction_multiplier = 2 if bidirectional else 1\n", "    activation_MB = batch_size * seq_length * hidden_dim * direction_multiplier * num_layers * dtype_bytes / (1024 ** 2)\n", "    total_MB = input_MB + activation_MB + model_param_MB_fixed\n", "    total_GB = total_MB / 1024\n", "    return input_MB, activation_MB, total_MB, total_GB"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd0d Example Usage"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Set model and input parameters\n", "batch_size = 64\n", "seq_length = 100\n", "input_dim = 3\n", "hidden_dim = 128\n", "num_layers = 2\n", "\n", "# Estimate memory\n", "input_MB, act_MB, total_MB, total_GB = estimate_lstm_gpu_memory(\n", "    batch_size, seq_length, input_dim, hidden_dim, num_layers\n", ")\n", "\n", "print(f\"Input Memory:       {input_MB:.2f} MB\")\n", "print(f\"Activation Memory:  {act_MB:.2f} MB\")\n", "print(f\"Total Memory:       {total_MB:.2f} MB ({total_GB:.2f} GB)\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcc8 Visualize Memory Usage for Varying Batch Sizes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "batch_sizes = range(16, 1025, 64)\n", "memories_MB = [\n", "    estimate_lstm_gpu_memory(bs, seq_length, input_dim, hidden_dim, num_layers)[2]\n", "    for bs in batch_sizes\n", "]\n", "\n", "plt.figure(figsize=(10, 5))\n", "plt.plot(batch_sizes, memories_MB, marker='o')\n", "plt.title(\"LSTM Total GPU Memory Usage vs Batch Size\")\n", "plt.xlabel(\"Batch Size\")\n", "plt.ylabel(\"Total Memory (MB)\")\n", "plt.grid(True)\n", "plt.tight_layout()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}
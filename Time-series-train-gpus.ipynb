{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a44e4f-e7c4-4347-8519-bc8f12b8f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure to launch this script using torchrun\n",
    "#bash: torchrun --nproc_per_node=4 train.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision import transforms\n",
    "\n",
    "# --- Your custom dataset ---\n",
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data  # Tensor of shape [N, 1, 3_000_000]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# --- Your 1D CNN Model ---\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=7, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Conv1d(16, 32, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 187000, 128),  # Adjust depending on input size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)  # Assuming 10-class output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# --- Training Function ---\n",
    "def train(rank, world_size):\n",
    "    # DDP setup\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "    # Dataset and Dataloader\n",
    "    dataset = TimeSeriesDataset(torch.randn(200_000, 1, 3_000_000), torch.randint(0, 10, (200_000,)))\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Model, Loss, Optimizer, AMP\n",
    "    model = CNN1D().to(rank)\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(50):\n",
    "        sampler.set_epoch(epoch)\n",
    "        model.train()\n",
    "        for i, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(rank, non_blocking=True), targets.to(rank, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            if i % 50 == 0 and rank == 0:\n",
    "                print(f\"[GPU {rank}] Epoch {epoch} Batch {i} Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Cleanup\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "# --- Entry Point ---\n",
    "def main():\n",
    "    world_size = torch.cuda.device_count()\n",
    "    mp.spawn(train, args=(world_size,), nprocs=world_size, join=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

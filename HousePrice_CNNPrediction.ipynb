{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1560967-a869-4a75-990a-4924ef9265b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca757bef-7895-4619-850a-276f05256738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3aa34c24-a538-4f81-863f-4c33c9e33158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of numeric dtype indexs: (13,)\n",
      "the lable name: ['Price']\n",
      "the shape of numeric dtype indexs: (12,)\n",
      "the shape of object dtype indexs: (8,)\n",
      "hi\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 418284 into shape (34857,1,2,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(features)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Reshape the features into a 2D format like a \"image\" (mimicking CNN's input format)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# The CNN expects input with shape (batch_size, channels, height, width). We'll reshape to simulate a single-channel \"image\".\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mreshape(features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Simulating a 1x2x3 \"image\" from the features\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Convert data to PyTorch tensors\u001b[39;00m\n\u001b[1;32m     29\u001b[0m features_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(features, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 418284 into shape (34857,1,2,3)"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"Melbourne_housing_FULL.csv\")\n",
    "\n",
    "numeric_features_index = data.dtypes[data.dtypes != 'object'].index\n",
    "print(\"the shape of numeric dtype indexs:\",numeric_features_index.shape)\n",
    "\n",
    "label_features_index = ['Price']\n",
    "numeric_features_index = numeric_features_index.drop(label_features_index)\n",
    "object_feature_index = data.dtypes[data.dtypes == 'object'].index\n",
    "\n",
    "print(\"the lable name:\", label_features_index)\n",
    "print(\"the shape of numeric dtype indexs:\",numeric_features_index.shape)\n",
    "print(\"the shape of object dtype indexs:\",object_feature_index.shape)\n",
    "\n",
    "\n",
    "# Example of feature engineering: let's say we are using the numerical columns\n",
    "features = data[numeric_features_index].values\n",
    "labels = data[label_features_index].values\n",
    "print('hi')\n",
    "\n",
    "# Standardize the features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Reshape the features into a 2D format like a \"image\" (mimicking CNN's input format)\n",
    "# The CNN expects input with shape (batch_size, channels, height, width). We'll reshape to simulate a single-channel \"image\".\n",
    "features = features.reshape(features.shape[0], 1, 2, 3)  # Simulating a 1x2x3 \"image\" from the features\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float32).view(-1, 1)  # Reshaping labels to (N, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_tensor, labels_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3292333-b597-432e-b17e-30d2ee01cc94",
   "metadata": {},
   "source": [
    "# Define the CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab13ba-fc4a-4140-b89f-531532e10942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousePriceCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HousePriceCNN, self).__init__()\n",
    "        \n",
    "        # Define CNN layers (convolution, pooling)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=2)  # Input: (1, 2, 3) -> Output: (32, 1, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=2)  # Output: (64, 1, 1)\n",
    "        \n",
    "        # Flatten the output from the CNN layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64, 128)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 1)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e8523-9ef0-42d3-b8ea-8c4f2addea8b",
   "metadata": {},
   "source": [
    "# Train the CNN Model\n",
    " Write the training loop for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44509ac9-9d16-4f4a-b97f-7e1764e910a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = HousePriceCNN()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"house_price_cnn.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f569848a-f139-4d82-b94c-111ddd3810b5",
   "metadata": {},
   "source": [
    "# Evaluate the model on the test set\n",
    "\n",
    "After training model can be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20911e1-fa5f-4b41-ac8c-c3b60b509166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predictions.append(outputs.numpy())\n",
    "        true_labels.append(labels.numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Print Mean Squared Error\n",
    "mse = np.mean((predictions - true_labels) ** 2)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eff6d1-f41d-4178-93bc-e6de903b6e9f",
   "metadata": {},
   "source": [
    "# Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78e851-900a-4d60-b8eb-2f9b9b2dd525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction\n",
    "new_data = np.array([[10000, 6, 5, 2500, 8, 1995]])  # Example feature values\n",
    "new_data = scaler.transform(new_data)  # Apply the same scaler\n",
    "\n",
    "# Reshape to simulate \"image-like\" input\n",
    "new_data = new_data.reshape(new_data.shape[0], 1, 2, 3)\n",
    "\n",
    "# Convert to tensor\n",
    "new_data_tensor = torch.tensor(new_data, dtype=torch.float32)\n",
    "\n",
    "# Make prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(new_data_tensor)\n",
    "    print(f\"Predicted House Price: ${prediction.item():,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5af2eb-70f9-4a0a-be13-2c165eb582fc",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- This is a basic CNN model for house price prediction. Although CNNs are typically used for image data, you can experiment with structured data in a similar \"image-like\" format for feature input.\n",
    "\n",
    "- For structured data like house prices, fully connected (dense) neural networks or other traditional machine learning models (e.g., decision trees, random forests, etc.) are usually more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccc393b7-b440-4551-b1c5-daff4e8034af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of preprossed train data: (34857, 354)\n",
      "df_all.shape,new_all.shape (34857, 3) (34857, 354)\n",
      "       Rooms  Distance  Suburb_Abbotsford  Suburb_Aberfeldie  \\\n",
      "0          2       2.5               True              False   \n",
      "1          2       2.5               True              False   \n",
      "2          2       2.5               True              False   \n",
      "3          3       2.5               True              False   \n",
      "4          3       2.5               True              False   \n",
      "...      ...       ...                ...                ...   \n",
      "34852      4       6.3              False              False   \n",
      "34853      2       6.3              False              False   \n",
      "34854      2       6.3              False              False   \n",
      "34855      3       6.3              False              False   \n",
      "34856      2       6.3              False              False   \n",
      "\n",
      "       Suburb_Airport West  Suburb_Albanvale  Suburb_Albert Park  \\\n",
      "0                    False             False               False   \n",
      "1                    False             False               False   \n",
      "2                    False             False               False   \n",
      "3                    False             False               False   \n",
      "4                    False             False               False   \n",
      "...                    ...               ...                 ...   \n",
      "34852                False             False               False   \n",
      "34853                False             False               False   \n",
      "34854                False             False               False   \n",
      "34855                False             False               False   \n",
      "34856                False             False               False   \n",
      "\n",
      "       Suburb_Albion  Suburb_Alphington  Suburb_Altona  ...  Suburb_Windsor  \\\n",
      "0              False              False          False  ...           False   \n",
      "1              False              False          False  ...           False   \n",
      "2              False              False          False  ...           False   \n",
      "3              False              False          False  ...           False   \n",
      "4              False              False          False  ...           False   \n",
      "...              ...                ...            ...  ...             ...   \n",
      "34852          False              False          False  ...           False   \n",
      "34853          False              False          False  ...           False   \n",
      "34854          False              False          False  ...           False   \n",
      "34855          False              False          False  ...           False   \n",
      "34856          False              False          False  ...           False   \n",
      "\n",
      "       Suburb_Wollert  Suburb_Wonga Park  Suburb_Wyndham Vale  \\\n",
      "0               False              False                False   \n",
      "1               False              False                False   \n",
      "2               False              False                False   \n",
      "3               False              False                False   \n",
      "4               False              False                False   \n",
      "...               ...                ...                  ...   \n",
      "34852           False              False                False   \n",
      "34853           False              False                False   \n",
      "34854           False              False                False   \n",
      "34855           False              False                False   \n",
      "34856           False              False                False   \n",
      "\n",
      "       Suburb_Yallambie  Suburb_Yarra Glen  Suburb_Yarraville  Suburb_croydon  \\\n",
      "0                 False              False              False           False   \n",
      "1                 False              False              False           False   \n",
      "2                 False              False              False           False   \n",
      "3                 False              False              False           False   \n",
      "4                 False              False              False           False   \n",
      "...                 ...                ...                ...             ...   \n",
      "34852             False              False               True           False   \n",
      "34853             False              False               True           False   \n",
      "34854             False              False               True           False   \n",
      "34855             False              False               True           False   \n",
      "34856             False              False               True           False   \n",
      "\n",
      "       Suburb_viewbank  Suburb_nan  \n",
      "0                False       False  \n",
      "1                False       False  \n",
      "2                False       False  \n",
      "3                False       False  \n",
      "4                False       False  \n",
      "...                ...         ...  \n",
      "34852            False       False  \n",
      "34853            False       False  \n",
      "34854            False       False  \n",
      "34855            False       False  \n",
      "34856            False       False  \n",
      "\n",
      "[34857 rows x 354 columns]\n"
     ]
    }
   ],
   "source": [
    "melbourne_data =  pd.read_csv(\"/home/gitika/My_Home/Python_ML_CNN/Regression/Melbourne_housing_FULL.csv\")\n",
    "#print(melbourne_data.describe())\n",
    "\n",
    "inp_f=['Rooms','Suburb','Distance']\n",
    "df_all = melbourne_data[inp_f]\n",
    "\n",
    "new_all = pd.get_dummies(df_all, dummy_na=True)\n",
    "print(\"the shape of preprossed train data:\",new_all.shape)\n",
    "print('df_all.shape,new_all.shape',df_all.shape,new_all.shape)\n",
    "#print(df_all)\n",
    "print(new_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f18f2-479e-4761-9a62-6c9b362752b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
